#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("scripts/pipelines/scripts/utils.dml") as utils;
source("scripts/builtin/bandit.dml") as bandit;

sep=$1
trainData = read($2, data_type="frame", format="csv", header=TRUE, 
  naStrings= ["NA", "null","  ","NaN", "_nan_", "", "?", " ", "nan", "inf", "NAN", "99999", "99999.00"], sep=sep);

testData = read($3, data_type="frame", format="csv", header=TRUE, 
 naStrings= ["NA", "null","  ","NaN", "_nan_", "", "?", " ", "nan", "inf", "NAN", "99999", "99999.00"], sep=sep);

metaInfo = read($4, data_type="frame", format="csv", header=FALSE);  
input = $5
pip = read(input+"pip.csv", data_type="frame", format="csv", header=FALSE);
hp = read(input+"hp.csv", data_type="matrix", format="csv", header=FALSE);
applyFunc = read(input+"applyFunc.csv", data_type="frame", format="csv", header=FALSE);
evalHp = read(input+"evalHp.csv", data_type="matrix", format="csv", header=FALSE);
# dirtyScore = read(input+"dirtyScore.csv", data_type="scalar", value_type="double");
cv = as.logical($6)
func = $7
out = $8
metaInfo = metaInfo[, 2:ncol(metaInfo)]

result = fit_pipeline(trainData, testData, metaInfo, pip[1,], applyFunc[1, ], hp[1,], func, evalHp, TRUE, FALSE)

header = frame(["dirty acc", "train acc", "test acc"], rows=1, cols=3)
result = as.frame(result)

writeRes = rbind(header, result)
print(toString(writeRes))
res = as.scalar(result[1, 3] > result[1, 1])
print("result: "+res)
write(writeRes, out+"/testAcc.csv", format="csv")

 
# UDF for evaluation  
# choice of parameters provided by API, X, Y, clone_X, evalFunHp (hyper-param), trainML (boolean for optimizing hp internally or passed by externally )
# UDF for evaluation  
# choice of parameters provided by API, X, Y, clone_X, evalFunHp (hyper-param), trainML (boolean for optimizing hp internally or passed by externally )
evalClassification = function(Matrix[Double] X, Matrix[Double] Y, Matrix[Double] Xtest, Matrix[Double] Ytest, Matrix[Double] Xorig=as.matrix(0),
  Matrix[Double] evalFunHp)
  
return(Matrix[Double] output)
{

  if(min(Y) == max(Y))
  {
    accuracy = as.matrix(0)
    a = 0
  }
  else {
    beta = multiLogReg(X=X, Y=Y, icpt=as.scalar(evalFunHp[1,1]), reg=as.scalar(evalFunHp[1,2]), tol=as.scalar(evalFunHp[1,3]), 
      maxi=1000, maxii=0, verbose=FALSE);
    [prob, yhat, accuracy] = multiLogRegPredict(Xtest, beta, Ytest, FALSE)
    error = yhat != Ytest
    a = getAccuracy(Ytest, yhat, TRUE)
    accuracy = as.matrix(accuracy)
    print("accuracy: "+toString(accuracy))
  }
  output = cbind(accuracy, evalFunHp)
}
evalRegression = function(Matrix[Double] X, Matrix[Double] Y, Matrix[Double] Xtest, Matrix[Double] Ytest, Matrix[Double] Xorig=as.matrix(0),
  Matrix[Double] evalFunHp)
return(Matrix[Double] output, Matrix[Double] error)
{
  Xtest = replace(target=Xtest, pattern = NaN, replacement = 0)
  X = replace(target=X, pattern = NaN, replacement = 0)
  if(is.na(as.scalar(evalFunHp[1,1])))
  {
    # do the gridsearch for hyper-parameters
    params = list("icpt","reg", "tol");
    paramRanges = list(seq(0,2,1),10^seq(0,-4), 10^seq(-6,-12));
    [B1, opt] = gridSearch(X=X, y=Y, train="lm", predict="RsquaredLoss",
      numB=ncol(X)+1, params=params, paramValues=paramRanges, cv=TRUE, cvk=3);
    evalFunHp = as.matrix(opt)  
  }
  beta = lm(X=X, y=Y, icpt=as.scalar(evalFunHp[1,1]), reg=as.scalar(evalFunHp[1,2]), tol=as.scalar(evalFunHp[1,3]), 
    maxi=1000, verbose = TRUE);
  pred = lmPredict(X=Xtest, B=beta, ytest=Ytest, icpt=as.scalar(evalFunHp[1,1]));
  error = pred != Ytest  
  accuracy = Rsquared(Xtest, Ytest, beta)
  rms = rmse(Xtest, Ytest, beta)
  print("r-squared: "+toString(accuracy))
  print("rmse: "+toString(rms))
  output = cbind(accuracy, evalFunHp)
}


# wape = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] loss) {
  # # loss = as.matrix(sum((y - X%*%B)^2));
  # pred = lmPredict(X=X, B=B, ytest=y);
  # WAPE = sum(abs(y - pred))/sum(abs(y)) #this will give the lose into range of [0,1]
  # WAPE = 1 - (WAPE/nrow(y))
  # loss = ifelse(is.na(as.matrix(WAPE)), as.matrix(0), as.matrix(WAPE))  
# }
# # # adjusted R-square
Rsquared = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] gain) {
  # loss = as.matrix(sum((y - X%*%B)^2));
  n = nrow(y)
  k = ncol(X)
  pred = lmPredict(X=X, B=B, ytest=y, verbose = TRUE);
  Rsqu = sum((y - pred)^2)/sum((y - mean(y))^2) #this will give the lose into range of [0,1]
  Rsqu = 1 - (Rsqu)
  # adjRsqu = 1 - (((n - 1)/(n - k - 1)) * (1 - Rsqu))
  gain = ifelse(is.na(as.matrix(Rsqu)), as.matrix(0), as.matrix(Rsqu))  
}
rmse = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] loss) {
  pred = lmPredict(X=X, B=B, ytest=y);
  rmse = sqrt(mean((y - pred)^2))
  loss = as.matrix(rmse)
}